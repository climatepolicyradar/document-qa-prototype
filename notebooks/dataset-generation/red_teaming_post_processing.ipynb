{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red-teaming postprocessing\n",
    "The goal here is to turn the Argilla labels labelled by Matyas into Score objects and merge them with the UNECE sprint labels. Important to note, that the policy-violation and UNECE sprint questions are opposing (\"does the answer violate the guideline\" and \"does the answer follow the guideline\" respectively) hence flipping the scores is required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argilla as rg\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(Path(\".\").absolute().parent.parent.as_posix())\n",
    "\n",
    "from src.evaluation.evaluator import Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matyasjuhasz/git/rag-labs/.venv/lib/python3.11/site-packages/argilla/client/client.py:178: UserWarning: No workspace configuration was detected. To work with Argilla datasets, specify a valid workspace name on `rg.init` or set it up through the `rg.set_workspace` function.\n",
      "  warnings.warn(\n",
      "/Users/matyasjuhasz/git/rag-labs/.venv/lib/python3.11/site-packages/argilla/client/client.py:195: UserWarning: You're connecting to Argilla Server 1.26.1 using a different client version (1.29.0).\n",
      "This may lead to potential compatibility issues during your experience.\n",
      "To ensure a seamless and optimized connection, we highly recommend aligning your client version with the server version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rg.init(\n",
    "    api_url=\"https://argilla.labs.climatepolicyradar.org/\",\n",
    "    api_key=os.getenv(\"ARGILLA_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5021559d505b43b9be7c3cb2a25d8bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/253 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "argilla_datasets = []\n",
    "\n",
    "batch_name = \"policy-violation-002\"\n",
    "user = \"matyas\"\n",
    "\n",
    "_argilla_ds = rg.FeedbackDataset.from_argilla(\n",
    "    name=batch_name, workspace=user\n",
    ")\n",
    "_ds = _argilla_ds.format_as(\"datasets\")\n",
    "\n",
    "_ds = _ds.map(\n",
    "    lambda x: {\n",
    "        \"user\": user,\n",
    "        \"batch_name\": batch_name,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c1/skfn6y1s1432yhzx3z_2zrph0000gn/T/ipykernel_71931/2949695185.py:11: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if row[\"policy-violation\"]:\n"
     ]
    }
   ],
   "source": [
    "answer_to_score = {\n",
    "    \"YES\": 1.0,\n",
    "    \"NO\": 0.0\n",
    "}\n",
    "\n",
    "scores = []\n",
    "\n",
    "for _, row in _ds.to_pandas().iterrows():\n",
    "    uuid = json.loads(row[\"metadata\"])[\"uuid\"]\n",
    "\n",
    "    if row[\"policy-violation\"]:\n",
    "        score = answer_to_score[row[\"policy-violation\"][0][\"value\"]]\n",
    "    \n",
    "        # We're only using this dataset for the positives on the violation\n",
    "        if score == 1.0:\n",
    "            scores.append(\n",
    "                Score(\n",
    "                    gen_uuid=uuid,\n",
    "                    score=score,\n",
    "                    type=\"human\",\n",
    "                    name=\"cpr-policy-violation\"\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/eval/cpr_generation_policy_red_teaming_scores.jsonl\", \"w\") as file:\n",
    "    for score in scores:\n",
    "        file.write(score.model_dump_json() + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
